{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgSj9rtIjkI1"
      },
      "source": [
        "### Imort something"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JtlEUZ3_krO",
        "outputId": "946b6f49-5c0e-4b3a-bb28-a1928b6d60a2"
      },
      "outputs": [],
      "source": [
        "! pip install joblib==1.1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnL6WmV3MD76",
        "outputId": "2b194872-d607-452b-fc0c-f2bfd00d5d2d"
      },
      "outputs": [],
      "source": [
        "#Check GPU version\n",
        "! /usr/local/cuda/bin/nvcc --version\n",
        "! nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3TGoH28QOys",
        "outputId": "30e43f43-7873-4946-8647-3bd67ae36375"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIvEtJ0Ljtvm",
        "outputId": "ed3742ca-123f-4dbe-e249-eebc9188ea86"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8I4DeO9AL4Q",
        "outputId": "312a7c19-b1c4-4aab-f4a7-f477b9dd4ac2"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "\n",
        "# URLs for the zip files\n",
        "links = [\n",
        "  'https://nihcc.box.com/shared/static/vfk49d74nhbxq3nqjg0900w5nvkorp5c.gz',\n",
        "  'https://nihcc.box.com/shared/static/i28rlmbvmfjbl8p2n3ril0pptcmcu9d1.gz',\n",
        "  'https://nihcc.box.com/shared/static/f1t00wrtdk94satdfb9olcolqx20z2jp.gz',\n",
        "\t'https://nihcc.box.com/shared/static/0aowwzs5lhjrceb3qp67ahp0rd1l1etg.gz',\n",
        "  'https://nihcc.box.com/shared/static/v5e3goj22zr6h8tzualxfsqlqaygfbsn.gz',\n",
        "\t'https://nihcc.box.com/shared/static/asi7ikud9jwnkrnkj99jnpfkjdes7l6l.gz',\n",
        "\t'https://nihcc.box.com/shared/static/jn1b4mw4n6lnh74ovmcjb8y48h8xj07n.gz',\n",
        "  'https://nihcc.box.com/shared/static/tvpxmn7qyrgl0w8wfh9kqfjskv6nmm1j.gz',\n",
        "\t'https://nihcc.box.com/shared/static/upyy3ml7qdumlgk2rfcvlb9k6gvqq2pj.gz',\n",
        "\t'https://nihcc.box.com/shared/static/l6nilvfa9cg3s28tqv1qc1olm3gnz54p.gz',\n",
        "\t'https://nihcc.box.com/shared/static/hhq8fkdgvcari67vfhs7ppg2w6ni4jze.gz',\n",
        "\t'https://nihcc.box.com/shared/static/ioqwiy20ihqwyr8pf4c24eazhh281pbu.gz'\n",
        "]\n",
        "\n",
        "for idx, link in enumerate(links):\n",
        "    fn = 'images_%02d.tar.gz' % (idx+1)\n",
        "    print('downloading'+fn+'...')\n",
        "    urllib.request.urlretrieve(link, fn)  # download the zip file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pEyWZ_a9ojkb"
      },
      "outputs": [],
      "source": [
        "#Make dictionary to save data\n",
        "#! mkdir /content/drive/MyDrive/ML\n",
        "#! mkdir /content/drive/MyDrive/ML/data\n",
        "#! mkdir /content/drive/MyDrive/ML/history_model\n",
        "#! mkdir /content/drive/MyDrive/ML/data/images\n",
        "#! mkdir /content/drive/MyDrive/ML/history_model/run_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2LAxqdR7ivX",
        "outputId": "cf2565d4-2dbb-4e03-bb3a-52661b6fb141"
      },
      "outputs": [],
      "source": [
        "#Unzip file\n",
        "! tar -xzvf images_01.tar.gz -C /content\n",
        "! rm images_01.tar.gz\n",
        "! tar -xzvf images_02.tar.gz -C /content\n",
        "! rm images_02.tar.gz\n",
        "! tar -xzvf images_03.tar.gz -C /content\n",
        "! rm images_03.tar.gz\n",
        "! tar -xzvf images_04.tar.gz -C /content\n",
        "! rm images_04.tar.gz\n",
        "! tar -xzvf images_05.tar.gz -C /content\n",
        "! rm images_05.tar.gz\n",
        "! tar -xzvf images_06.tar.gz -C /content\n",
        "! rm images_06.tar.gz\n",
        "! tar -xzvf images_07.tar.gz -C /content\n",
        "! rm images_07.tar.gz\n",
        "! tar -xzvf images_08.tar.gz -C /content\n",
        "! rm images_08.tar.gz\n",
        "! tar -xzvf images_09.tar.gz -C /content\n",
        "! rm images_09.tar.gz\n",
        "! tar -xzvf images_10.tar.gz -C /content\n",
        "! rm images_10.tar.gz\n",
        "! tar -xzvf images_11.tar.gz -C /content\n",
        "! rm images_11.tar.gz\n",
        "! tar -xzvf images_12.tar.gz -C /content\n",
        "! rm images_12.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptPYTcSIjkI9"
      },
      "outputs": [],
      "source": [
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import os\n",
        "import sys\n",
        "import pprint\n",
        "import warnings\n",
        "import json\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "from torchvision.models import densenet121 as torch_densenet121\n",
        "\n",
        "#from densenet import densenet121\n",
        "#import util"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHdjwWs2jkJA"
      },
      "source": [
        "### DenseNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bcR3dAIjkJB"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "from collections import OrderedDict\n",
        "\n",
        "__all__ = ['DenseNet', 'densenet121', 'densenet169', 'densenet201', 'densenet161']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'densenet121': 'https://download.pytorch.org/models/densenet121-a639ec97.pth',\n",
        "    'densenet169': 'https://download.pytorch.org/models/densenet169-b2777c0a.pth',\n",
        "    'densenet201': 'https://download.pytorch.org/models/densenet201-c1103571.pth',\n",
        "    'densenet161': 'https://download.pytorch.org/models/densenet161-8d451a50.pth',\n",
        "}\n",
        "\n",
        "\n",
        "def densenet121(pretrained=False, **kwargs):\n",
        "    r\"\"\"Densenet-121 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    #model = DenseNet(num_init_features=64, growth_rate=32, block_config=(6, 12, 24, 16), **kwargs)\n",
        "    model = torch_densenet121(weights=\"IMAGENET1K_V1\" if pretrained else None)  # 使用 PyTorch 預訓練的模型\n",
        "    \"\"\"\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['densenet121']))\n",
        "    \"\"\"\n",
        "    return model\n",
        "\n",
        "\n",
        "def densenet169(pretrained=False, **kwargs):\n",
        "    r\"\"\"Densenet-169 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = DenseNet(num_init_features=64, growth_rate=32, block_config=(6, 12, 32, 32),\n",
        "                     **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['densenet169']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def densenet201(pretrained=False, **kwargs):\n",
        "    r\"\"\"Densenet-201 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = DenseNet(num_init_features=64, growth_rate=32, block_config=(6, 12, 48, 32),\n",
        "                     **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['densenet201']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def densenet161(pretrained=False, **kwargs):\n",
        "    r\"\"\"Densenet-161 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = DenseNet(num_init_features=96, growth_rate=48, block_config=(6, 12, 36, 24),\n",
        "                     **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['densenet161']))\n",
        "    return model\n",
        "\n",
        "\n",
        "class _DenseLayer(nn.Sequential):\n",
        "    def __init__(self, num_input_features, growth_rate, bn_size, drop_rate):\n",
        "        super(_DenseLayer, self).__init__()\n",
        "        self.add_module('norm.1', nn.BatchNorm2d(num_input_features)),\n",
        "        self.add_module('relu.1', nn.ReLU(inplace=True)),\n",
        "        self.add_module('conv.1', nn.Conv2d(num_input_features, bn_size *\n",
        "                        growth_rate, kernel_size=1, stride=1, bias=False)),\n",
        "        self.add_module('norm.2', nn.BatchNorm2d(bn_size * growth_rate)),\n",
        "        self.add_module('relu.2', nn.ReLU(inplace=True)),\n",
        "        self.add_module('conv.2', nn.Conv2d(bn_size * growth_rate, growth_rate,\n",
        "                        kernel_size=3, stride=1, padding=1, bias=False)),\n",
        "        self.drop_rate = drop_rate\n",
        "\n",
        "    def forward(self, x):\n",
        "        new_features = super(_DenseLayer, self).forward(x)\n",
        "        if self.drop_rate > 0:\n",
        "            new_features = F.dropout(new_features, p=self.drop_rate, training=self.training)\n",
        "        return torch.cat([x, new_features], 1)\n",
        "\n",
        "\n",
        "class _DenseBlock(nn.Sequential):\n",
        "    def __init__(self, num_layers, num_input_features, bn_size, growth_rate, drop_rate):\n",
        "        super(_DenseBlock, self).__init__()\n",
        "        for i in range(num_layers):\n",
        "            layer = _DenseLayer(num_input_features + i * growth_rate, growth_rate, bn_size, drop_rate)\n",
        "            self.add_module('denselayer%d' % (i + 1), layer)\n",
        "\n",
        "\n",
        "class _Transition(nn.Sequential):\n",
        "    def __init__(self, num_input_features, num_output_features):\n",
        "        super(_Transition, self).__init__()\n",
        "        self.add_module('norm', nn.BatchNorm2d(num_input_features))\n",
        "        self.add_module('relu', nn.ReLU(inplace=True))\n",
        "        self.add_module('conv', nn.Conv2d(num_input_features, num_output_features,\n",
        "                                          kernel_size=1, stride=1, bias=False))\n",
        "        self.add_module('pool', nn.AvgPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "\n",
        "class DenseNet(nn.Module):\n",
        "    r\"\"\"Densenet-BC model class, based on\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "    Args:\n",
        "        growth_rate (int) - how many filters to add each layer (`k` in paper)\n",
        "        block_config (list of 4 ints) - how many layers in each pooling block\n",
        "        num_init_features (int) - the number of filters to learn in the first convolution layer\n",
        "        bn_size (int) - multiplicative factor for number of bottle neck layers\n",
        "          (i.e. bn_size * k features in the bottleneck layer)\n",
        "        drop_rate (float) - dropout rate after each dense layer\n",
        "        num_classes (int) - number of classification classes\n",
        "    \"\"\"\n",
        "    def __init__(self, growth_rate=32, block_config=(6, 12, 24, 16),\n",
        "                 num_init_features=64, bn_size=4, drop_rate=0, num_classes=1000):\n",
        "\n",
        "        super(DenseNet, self).__init__()\n",
        "\n",
        "        # First convolution\n",
        "        self.features = nn.Sequential(OrderedDict([\n",
        "            ('conv0', nn.Conv2d(3, num_init_features, kernel_size=7, stride=2, padding=3, bias=False)),\n",
        "            ('norm0', nn.BatchNorm2d(num_init_features)),\n",
        "            ('relu0', nn.ReLU(inplace=True)),\n",
        "            ('pool0', nn.MaxPool2d(kernel_size=3, stride=2, padding=1)),\n",
        "        ]))\n",
        "\n",
        "        # Each denseblock\n",
        "        num_features = num_init_features\n",
        "        for i, num_layers in enumerate(block_config):\n",
        "            block = _DenseBlock(num_layers=num_layers, num_input_features=num_features,\n",
        "                                bn_size=bn_size, growth_rate=growth_rate, drop_rate=drop_rate)\n",
        "            self.features.add_module('denseblock%d' % (i + 1), block)\n",
        "            num_features = num_features + num_layers * growth_rate\n",
        "            if i != len(block_config) - 1:\n",
        "                trans = _Transition(num_input_features=num_features, num_output_features=num_features // 2)\n",
        "                self.features.add_module('transition%d' % (i + 1), trans)\n",
        "                num_features = num_features // 2\n",
        "\n",
        "        # Final batch norm\n",
        "        self.features.add_module('norm5', nn.BatchNorm2d(num_features))\n",
        "\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "        # Linear layer\n",
        "        self.classifier = nn.Linear(num_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.features(x)\n",
        "        out = F.relu(features, inplace=True)\n",
        "        out = self.gap(out).view(features.size(0), -1)\n",
        "        out = self.classifier(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rw3IHThZjkJD"
      },
      "source": [
        "### util"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vG67kKEejkJE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "import sklearn.metrics\n",
        "import argparse\n",
        "import os\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def get_parser():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--model\", default=\"densenet\", type=str)\n",
        "    parser.add_argument(\"--optimizer\", default=\"adam\", type=str)\n",
        "    parser.add_argument(\"--lr\", default=0.0001, type=float)\n",
        "    parser.add_argument(\"--weight_decay\", default=0.0, type=float)\n",
        "    parser.add_argument(\"--drop_rate\", default=0.0, type=float)\n",
        "    parser.add_argument(\"--epochs\", default=15, type=int)\n",
        "    parser.add_argument(\"--batch_size\", default=16, type=int)\n",
        "    parser.add_argument(\"--workers\", default=8, type=int)\n",
        "    parser.add_argument(\"--seed\", default=123456, type=int)\n",
        "    parser.add_argument(\"--tag\", default=\"\", type=str)\n",
        "    parser.add_argument(\"--toy\", action=\"store_true\")\n",
        "    parser.add_argument(\"--save_path\", default=None, type=str)\n",
        "    parser.add_argument(\"--scale\", default=224, type=int)\n",
        "    parser.add_argument(\"--horizontal_flip\", action=\"store_true\")\n",
        "    parser.add_argument(\"--verbose\", action=\"store_true\")\n",
        "    parser.add_argument(\"--scratch\", action=\"store_true\")\n",
        "    parser.add_argument(\"--train_weighted\", action=\"store_true\")\n",
        "    parser.add_argument(\"--valid_weighted\", action=\"store_true\")\n",
        "    parser.add_argument(\"--size\", default=None, type=str)\n",
        "    return parser\n",
        "\n",
        "\n",
        "\n",
        "class Dataset(data.Dataset):\n",
        "    def __init__(self, args, data_split):\n",
        "        super(Dataset, self).__init__()\n",
        "\n",
        "        if args.tag:\n",
        "            tag = \"_\"+args.tag\n",
        "            df = pd.read_csv(os.path.join(\"/content/drive/MyDrive/ML/data/%s%s.csv\" % (data_split, tag)))\n",
        "        else:\n",
        "            df = pd.read_csv(os.path.join(\"/content/drive/MyDrive/ML/data/%s.csv\" % (data_split)))\n",
        "\n",
        "        if args.toy:\n",
        "            df = df.sample(frac=0.01)\n",
        "\n",
        "        self.df = df\n",
        "        self.img_paths = df[\"Path\"].tolist()\n",
        "        self.pathologies = [col for col in df.columns.values if col != \"Path\"]\n",
        "\n",
        "        self.labels = df[self.pathologies].values.astype(int)\n",
        "\n",
        "        self.n_classes = self.labels.shape[1]\n",
        "\n",
        "        normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        if data_split == \"train\":\n",
        "            transforms_lst = [\n",
        "                transforms.Resize((args.scale, args.scale)),\n",
        "                transforms.RandomHorizontalFlip() if args.horizontal_flip else None,\n",
        "                transforms.ToTensor(),\n",
        "                normalize,\n",
        "            ]\n",
        "            self.transform = transforms.Compose([t for t in transforms_lst if t])\n",
        "        else:\n",
        "            self.transform = transforms.Compose([\n",
        "                transforms.Resize((args.scale, args.scale)),\n",
        "                transforms.ToTensor(),\n",
        "                normalize,\n",
        "            ])\n",
        "        self.df = df\n",
        "\n",
        "\n",
        "        if (data_split == \"train\" and args.train_weighted) or (data_split == \"valid\" and args.valid_weighted):\n",
        "            self.get_weights(args, data_split)\n",
        "\n",
        "\n",
        "    def get_weights(self, args, data_split):\n",
        "\n",
        "        self.use_gpu = torch.cuda.is_available()\n",
        "        p_count = (self.labels == 1).sum(axis = 0)\n",
        "        self.p_count = p_count\n",
        "        n_count = (self.labels == 0).sum(axis = 0)\n",
        "        total = p_count + n_count\n",
        "\n",
        "        # invert *opposite* weights to obtain weighted loss\n",
        "        # (positives weighted higher, all weights same across batches, and p_weight + n_weight == 1)\n",
        "        p_weight = n_count / total\n",
        "        n_weight = p_count / total\n",
        "\n",
        "        self.p_weight_loss = Variable(torch.FloatTensor(p_weight), requires_grad=False)\n",
        "        self.n_weight_loss = Variable(torch.FloatTensor(n_weight), requires_grad=False)\n",
        "\n",
        "        print (\"Positive %s Loss weight:\" % data_split, self.p_weight_loss.data.numpy())\n",
        "        print (\"Negative %s Loss weight:\" % data_split, self.n_weight_loss.data.numpy())\n",
        "        random_loss = sum((p_weight[i] * p_count[i] + n_weight[i] * n_count[i]) *\\\n",
        "                                               -np.log(0.5) / total[i] for i in range(self.n_classes)) / self.n_classes\n",
        "        print (\"Random %s Loss:\" % data_split, random_loss)\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img = Image.open(self.img_paths[index]).convert(\"RGB\")\n",
        "        label = self.labels[index]\n",
        "\n",
        "        return self.transform(img), torch.LongTensor(label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def weighted_loss(self, preds, target, epoch=1):\n",
        "\n",
        "        weights = target.type(torch.FloatTensor) * (self.p_weight_loss.expand_as(target)) + \\\n",
        "                  (target == 0).type(torch.FloatTensor) * (self.n_weight_loss.expand_as(target))\n",
        "        if self.use_gpu:\n",
        "            weights = weights.cuda()\n",
        "        loss = 0.0\n",
        "        for i in range(self.n_classes):\n",
        "            loss += nn.functional.binary_cross_entropy_with_logits(preds[:,i], target[:,i], weight=weights[:,i])\n",
        "        return loss / self.n_classes\n",
        "\n",
        "\n",
        "def evaluate(gts, probabilities, pathologies, use_only_index = None):\n",
        "    assert(np.all(probabilities >= 0) == True)\n",
        "    assert(np.all(probabilities <= 1) == True)\n",
        "\n",
        "    def compute_metrics_for_class(i):\n",
        "         p, r, t = sklearn.metrics.precision_recall_curve(gts[:, i], probabilities[:, i])\n",
        "         PR_AUC = sklearn.metrics.auc(r, p)\n",
        "         ROC_AUC = sklearn.metrics.roc_auc_score(gts[:, i], probabilities[:, i])\n",
        "         F1 = sklearn.metrics.f1_score(gts[:, i], preds[:, i])\n",
        "         acc = sklearn.metrics.accuracy_score(gts[:, i], preds[:, i])\n",
        "         count = np.sum(gts[:, i])\n",
        "         return PR_AUC, ROC_AUC, F1, acc, count\n",
        "\n",
        "    PR_AUCs = []\n",
        "    ROC_AUCs = []\n",
        "    F1s = []\n",
        "    accs = []\n",
        "    counts = []\n",
        "    preds = probabilities >= 0.5\n",
        "\n",
        "    classes = [use_only_index] if use_only_index is not None else range(len(gts[0]))\n",
        "\n",
        "    for i in classes:\n",
        "        try:\n",
        "            PR_AUC, ROC_AUC, F1, acc, count = compute_metrics_for_class(i)\n",
        "        except ValueError:\n",
        "            continue\n",
        "        PR_AUCs.append(PR_AUC)\n",
        "        ROC_AUCs.append(ROC_AUC)\n",
        "        F1s.append(F1)\n",
        "        accs.append(acc)\n",
        "        counts.append(count)\n",
        "        print('Class: {!s} Count: {:d} PR AUC: {:.4f} ROC AUC: {:.4f} F1: {:.3f} Acc: {:.3f}'.format(pathologies[i], count, PR_AUC, ROC_AUC, F1, acc))\n",
        "\n",
        "    avg_PR_AUC = np.average(PR_AUCs)\n",
        "    avg_ROC_AUC = np.average(ROC_AUCs, weights=counts)\n",
        "    avg_F1 = np.average(F1s, weights=counts)\n",
        "\n",
        "    print('Avg PR AUC: {:.3f}'.format(avg_PR_AUC))\n",
        "    print('Avg ROC AUC: {:.3f}'.format(avg_ROC_AUC))\n",
        "    print('Avg F1: {:.3f}'.format(avg_F1))\n",
        "    return avg_PR_AUC, avg_ROC_AUC, avg_F1\n",
        "\n",
        "\n",
        "def loader_to_gts(data_loader):\n",
        "    gts = []\n",
        "    for (inputs, labels) in data_loader:\n",
        "        for label in labels.cpu().numpy().tolist():\n",
        "            gts.append(label)\n",
        "    gts = np.array(gts)\n",
        "    return gts\n",
        "\n",
        "\n",
        "def load_data(args):\n",
        "\n",
        "    train_dataset = Dataset(args, \"train_F\")\n",
        "    valid_dataset = Dataset(args, \"valid_female\")\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "            train_dataset, batch_size=args.batch_size, shuffle=True,\n",
        "            num_workers=args.workers, pin_memory=True, sampler=None)\n",
        "\n",
        "    valid_loader = torch.utils.data.DataLoader(\n",
        "            valid_dataset, batch_size=args.batch_size, shuffle=False,\n",
        "            num_workers=args.workers, pin_memory=True, sampler=None)\n",
        "\n",
        "    return train_loader, valid_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGv5nGWZjkJG"
      },
      "source": [
        "### train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LpDL40BFFJv"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "class DenseNet_train(nn.Module):\n",
        "    def __init__(self, config, nclasses):\n",
        "        super(DenseNet_train, self).__init__()\n",
        "        self.model_ft = densenet121(pretrained=not config.scratch, drop_rate=config.drop_rate)\n",
        "        num_ftrs = self.model_ft.classifier.in_features\n",
        "        self.model_ft.classifier = nn.Linear(num_ftrs, nclasses)\n",
        "        self.config = config\n",
        "    def forward(self, x):\n",
        "        return self.model_ft(x)\n",
        "\n",
        "def transform_data(data, use_gpu, train=False):\n",
        "    inputs, labels = data\n",
        "    # GPU\n",
        "    labels = labels.type(torch.FloatTensor)\n",
        "    if use_gpu is True:\n",
        "        inputs = inputs.cuda()\n",
        "        labels = labels.cuda()\n",
        "    #\n",
        "    with torch.no_grad():\n",
        "        inputs = Variable(inputs, requires_grad=False)\n",
        "        labels = Variable(labels, requires_grad=False)\n",
        "    return inputs, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qV20lc4rjkJH",
        "outputId": "dffeb656-54fb-4aaf-f912-daf4d81348f1"
      },
      "outputs": [],
      "source": [
        "def train_epoch(epoch, args, model, loader, criterion, optimizer):\n",
        "    model.train()\n",
        "    batch_losses = []\n",
        "    start_time = time.time() #記錄初始時間\n",
        "\n",
        "    for batch_idx, data in enumerate(loader):\n",
        "        batch_start_time = time.time()  #每個batch開始時間\n",
        "        inputs, labels = transform_data(data, True, train=True)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels, epoch=epoch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #計算累計時間\n",
        "        cumulative_time = time.time() - start_time\n",
        "        print(\"Epoch: {:d} Batch: {:d} ({:d}) Train Loss: {:.6f} Time Elapsed: {:.2f} seconds\".format(\n",
        "            epoch, batch_idx, args.batch_size, loss.data, cumulative_time))\n",
        "        sys.stdout.flush()\n",
        "\n",
        "        #batch_losses.append(loss.data) #CPU\n",
        "        batch_losses.append(loss.data.cpu().numpy()) #GPU\n",
        "    train_loss = np.mean(batch_losses)\n",
        "    print(\"Training Loss: {:.6f}\".format(train_loss))\n",
        "    return train_loss\n",
        "\n",
        "\n",
        "def test_epoch(model, loader, criterion, epoch=1):\n",
        "    \"\"\"\n",
        "    Returns: (AUC, ROC AUC, F1, validation loss)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    test_losses = []\n",
        "    outs = []\n",
        "    gts = []\n",
        "    for data in loader:\n",
        "        #for gt in data[1].numpy().tolist(): #CPU\n",
        "        for gt in data[1].cpu().numpy().tolist(): #GPU\n",
        "            gts.append(gt)\n",
        "        inputs, labels = transform_data(data, True, train=False)\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels, epoch=epoch)\n",
        "        #test_losses.append(loss.data) #CPU\n",
        "        test_losses.append(loss.data.cpu().numpy()) #GPU\n",
        "        out = torch.sigmoid(outputs).data.cpu().numpy()\n",
        "        outs.extend(out)\n",
        "    avg_loss = np.mean(test_losses)\n",
        "    print(\"Validation Loss: {:.6f}\".format(avg_loss))\n",
        "    outs = np.array(outs)\n",
        "    gts = np.array(gts)\n",
        "    avg_pr_auc, avg_roc_auc, avg_f1 = evaluate(gts, outs, loader.dataset.pathologies)\n",
        "    print(f\"Validation AUC: PR AUC={avg_pr_auc:.3f}, ROC AUC={avg_roc_auc:.3f}, F1 Score={avg_f1:.3f}\")\n",
        "    return evaluate(gts, outs, loader.dataset.pathologies) + (avg_loss,)\n",
        "\n",
        "\n",
        "def get_loss(dataset, weighted):\n",
        "\n",
        "    criterion = nn.MultiLabelSoftMarginLoss()\n",
        "\n",
        "    def loss(preds, target, epoch):\n",
        "\n",
        "        if weighted:\n",
        "\n",
        "            return dataset.weighted_loss(preds, target, epoch=epoch)\n",
        "\n",
        "        else:\n",
        "\n",
        "            return criterion(preds, target)\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "def run(args):\n",
        "\n",
        "    use_gpu = torch.cuda.is_available()\n",
        "    model = None\n",
        "\n",
        "    train, val = load_data(args)\n",
        "    nclasses = train.dataset.n_classes\n",
        "    print(\"Number of classes:\", nclasses)\n",
        "\n",
        "    if args.model == \"densenet\":\n",
        "        model = DenseNet_train(args, nclasses)\n",
        "    else:\n",
        "        print(\"{} is not a valid model.\".format(args.model))\n",
        "\n",
        "    if use_gpu:\n",
        "        model = model.cuda()\n",
        "\n",
        "    train_criterion = get_loss(train.dataset, args.train_weighted)\n",
        "    val_criterion = get_loss(val.dataset, args.valid_weighted)\n",
        "\n",
        "    if args.optimizer == \"adam\":\n",
        "        optimizer = optim.Adam(\n",
        "                       filter(lambda p: p.requires_grad, model.model_ft.parameters()),\n",
        "                       lr=args.lr,\n",
        "                       weight_decay=args.weight_decay)\n",
        "    elif args.optimizer == \"rmsprop\":\n",
        "        optimizer = optim.RMSprop(\n",
        "                       filter(lambda p: p.requires_grad, model.model_ft.parameters()),\n",
        "                       lr=args.lr,\n",
        "                       weight_decay=args.weight_decay)\n",
        "    else:\n",
        "        print(\"{} is not a valid optimizer.\".format(args.optimizer))\n",
        "\n",
        "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, patience=1, threshold=0.001, factor=0.1)\n",
        "    best_model_wts, best_loss = model.state_dict(), float(\"inf\")\n",
        "\n",
        "    #畫loss、AUC圖\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "    roc_aucs = []\n",
        "    elapsed_times = []\n",
        "    start_time = time.time()\n",
        "\n",
        "    plt.ion()\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
        "    ax1.set_title(\"Training and Validation Loss Over Time\")\n",
        "    ax1.set_xlabel(\"Elapsed Time (s)\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    ax2.set_title(\"Validation ROC AUC Over Time\")\n",
        "    ax2.set_xlabel(\"Elapsed Time (s)\")\n",
        "    ax2.set_ylabel(\"ROC AUC\")\n",
        "\n",
        "    ax1.plot([], [], label=\"Train Loss\", color=\"blue\")\n",
        "    ax1.plot([], [], label=\"Validation Loss\", color=\"orange\")\n",
        "    ax1.legend(loc='upper right')\n",
        "\n",
        "    ax2.plot([], [], label=\"ROC AUC\", color=\"green\")\n",
        "    ax2.legend(loc='upper right')\n",
        "\n",
        "\n",
        "    counter = 0\n",
        "    for epoch in range(1, args.epochs + 1):\n",
        "        print(\"Epoch {}/{}\".format(epoch, args.epochs))\n",
        "        print(\"-\" * 10)\n",
        "\n",
        "        train_loss = train_epoch(epoch, args, model, train,train_criterion, optimizer)\n",
        "        #picture\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        _, epoch_auc, _, valid_loss = test_epoch(model, val, val_criterion, epoch)\n",
        "        #picture\n",
        "        valid_losses.append(valid_loss)\n",
        "        roc_aucs.append(epoch_auc)\n",
        "        elapsed_time = time.time() - start_time\n",
        "        elapsed_times.append(elapsed_time)\n",
        "\n",
        "\n",
        "        scheduler.step(valid_loss)\n",
        "\n",
        "        if (valid_loss < best_loss):\n",
        "            best_loss = valid_loss\n",
        "            best_model_wts = model.state_dict()\n",
        "            counter = 0\n",
        "        else:\n",
        "            counter += 1\n",
        "\n",
        "        if counter > 3:\n",
        "            break\n",
        "\n",
        "        #即時更新圖\n",
        "        ax1.plot(elapsed_times, train_losses, label=\"Train Loss\", color=\"blue\")\n",
        "        ax1.plot(elapsed_times, valid_losses, label=\"Validation Loss\", color=\"orange\")\n",
        "\n",
        "        ax2.plot(elapsed_times, roc_aucs, label=\"ROC AUC\", color=\"green\")\n",
        "\n",
        "        fig.canvas.draw()\n",
        "        plt.pause(0.01)\n",
        "\n",
        "        torch.save(best_model_wts, os.path.join(args.save_path, \"val%f_train%f_epoch%d\" % (valid_loss, train_loss, epoch)))\n",
        "\n",
        "    plt.ioff()\n",
        "    plt.show()\n",
        "    print(\"Best Validation Loss:\", best_loss)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \"\"\"\n",
        "    Usage\n",
        "        Download the images data at https://nihcc.app.box.com/v/ChestXray-NIHCC\n",
        "        To train on the original labels:\n",
        "            python train.py --save_path run_dir --model densenet --batch_size 8 --horizontal_flip --epochs 10 --lr 0.0001 --train_weighted --valid_weighted --scale 512\n",
        "        To train on the relabels:\n",
        "            python train.py --save_path run_dir --model densenet --batch_size 8 --horizontal_flip --epochs 10 --lr 0.0001 --train_weighted --valid_weighted --scale 512 --tag relabeled\n",
        "    \"\"\"\n",
        "\n",
        "    args = argparse.Namespace(\n",
        "        model=\"densenet\",\n",
        "        optimizer=\"adam\",\n",
        "        lr=0.0001,\n",
        "        weight_decay=0.0,\n",
        "        drop_rate=0.0,\n",
        "        epochs=10,\n",
        "        batch_size=16,\n",
        "        workers=4,\n",
        "        seed = 123456,\n",
        "        tag = \"\",\n",
        "        toy = False,\n",
        "        save_path=\"drive/MyDrive/ML/history_model/run_dir\",  # 提供一個默認的保存路徑\n",
        "        scale=224,\n",
        "        horizontal_flip = False,\n",
        "        verbose = False,\n",
        "        scratch=False,  # 控制是否從頭開始訓練\n",
        "        train_weighted=False,  # 是否加權訓練損失\n",
        "        valid_weighted=False,  # 是否加權驗證損失\n",
        "        size = None\n",
        "    )\n",
        "    \"\"\"\n",
        "    parser = get_parser()\n",
        "    args = parser.parse_args()\n",
        "    pp = pprint.PrettyPrinter()\n",
        "    pp.pprint(vars(args))\n",
        "    \"\"\"\n",
        "\n",
        "    if not os.path.isdir(args.save_path):\n",
        "        os.makedirs(args.save_path)\n",
        "\n",
        "    with open(os.path.join(args.save_path, \"params.txt\"), 'w') as out:\n",
        "        json.dump(vars(args), out, indent=4)\n",
        "    run(args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dV2DGmyoctf"
      },
      "source": [
        "### Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItO-F5fmr9WD"
      },
      "outputs": [],
      "source": [
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_age/middle/ep_10/predict\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_age/middle/ep_10/predict/female\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_age/middle/ep_10/predict/female/predictions\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_age/middle/ep_10/predict\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_age/middle/ep_10/predict/male\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_age/middle/ep_10/predict/male/predictions\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_age/middle/ep_10/predict\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_age/middle/ep_10/predict/young\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_age/middle/ep_10/predict/young/predictions\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_age/middle/ep_10/predict\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_age/middle/ep_10/predict/middle\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_age/middle/ep_10/predict/middle/predictions\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_age/middle/ep_10/predict\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_age/middle/ep_10/predict/old\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_age/middle/ep_10/predict/old/predictions\n",
        "\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_age/young/ep_10/predict\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_age/young/ep_10/predict/female\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_age/young/ep_10/predict/female/predictions\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_age/young/ep_10/predict\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_age/young/ep_10/predict/male\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_age/young/ep_10/predict/male/predictions\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_age/young/ep_10/predict\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_age/young/ep_10/predict/young\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_age/young/ep_10/predict/young/predictions\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_age/young/ep_10/predict\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_age/young/ep_10/predict/middle\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_age/young/ep_10/predict/middle/predictions\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_age/young/ep_10/predict\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_age/young/ep_10/predict/old\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_age/young/ep_10/predict/old/predictions\n",
        "\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_gender/Male/ep_10/predict\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_gender/Male/ep_10/predict/female\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_gender/Male/ep_10/predict/female/predictions\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_gender/Male/ep_10/predict\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_gender/Male/ep_10/predict/male\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_gender/Male/ep_10/predict/male/predictions\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_gender/Male/ep_10/predict\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_gender/Male/ep_10/predict/young\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_gender/Male/ep_10/predict/young/predictions\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_gender/Male/ep_10/predict\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_gender/Male/ep_10/predict/middle\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_gender/Male/ep_10/predict/middle/predictions\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_gender/Male/ep_10/predict\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_gender/Male/ep_10/predict/old\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_gender/Male/ep_10/predict/old/predictions\n",
        "\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_gender/Female/ep_10/predict\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_gender/Female/ep_10/predict/female\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_gender/Female/ep_10/predict/female/predictions\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_gender/Female/ep_10/predict\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_gender/Female/ep_10/predict/male\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_gender/Female/ep_10/predict/male/predictions\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_gender/Female/ep_10/predict\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_gender/Female/ep_10/predict/young\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_gender/Female/ep_10/predict/young/predictions\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_gender/Female/ep_10/predict\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_gender/Female/ep_10/predict/middle\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_gender/Female/ep_10/predict/middle/predictions\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_gender/Female/ep_10/predict\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_gender/Female/ep_10/predict/old\n",
        "# ! mkdir /content/drive/MyDrive/ML/history_model/CheXneXt_gender/Female/ep_10/predict/old/predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "53ATr1mQ4WzG",
        "outputId": "9b105c09-3686-41b5-d2e2-5ca62ed23829"
      },
      "outputs": [],
      "source": [
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import torch\n",
        "import time\n",
        "import os\n",
        "import json\n",
        "import argparse\n",
        "import itertools\n",
        "from sklearn import metrics\n",
        "#import util\n",
        "#from train import transform_data, DenseNet\n",
        "from joblib import Memory\n",
        "\n",
        "\n",
        "memory = Memory(location='./cache', verbose=0)\n",
        "\n",
        "\n",
        "# convert dictionary to object\n",
        "class Struct:\n",
        "    def __init__(self, **entries):\n",
        "        self.__dict__.update(entries)\n",
        "\n",
        "\n",
        "def load_model(args, load_path, nclasses):\n",
        "    #print(args)\n",
        "    print(nclasses)\n",
        "    model = DenseNet_train(args, nclasses)\n",
        "    #model.load_state_dict(torch.load(load_path))\n",
        "    model.load_state_dict(torch.load(load_path))\n",
        "    model = model.cuda()\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "\n",
        "@memory.cache\n",
        "def get_model_predictions(args_dict, model_path, loader):\n",
        "\n",
        "    args = Struct(**args_dict)\n",
        "\n",
        "    model = load_model(args, model_path, loader.dataset.n_classes)\n",
        "    outs = []\n",
        "    # gather predictions for all images in the validation set\n",
        "    for i, (inputs, labels) in enumerate(loader):\n",
        "        inputs, _ = transform_data((inputs, labels), use_gpu=True)\n",
        "        outputs = model(inputs)\n",
        "        out = torch.sigmoid(outputs).data.cpu().numpy()\n",
        "        outs.append(out)\n",
        "    outs = np.concatenate(outs, axis=0)\n",
        "    return outs\n",
        "\n",
        "\n",
        "@memory.cache\n",
        "def get_loader_on_split(args_dict, split):\n",
        "\n",
        "    if \"tag\" not in args_dict:\n",
        "        args_dict[\"tag\"] = args_dict[\"size\"]\n",
        "\n",
        "    args = Struct(**args_dict)\n",
        "\n",
        "    dataset = Dataset(args, split)\n",
        "\n",
        "    loader = torch.utils.data.DataLoader(\n",
        "                    dataset, batch_size=args.batch_size, shuffle=False,\n",
        "                    num_workers=args.workers, pin_memory=False)\n",
        "    return loader\n",
        "\n",
        "\n",
        "def optimal_threshold_compute(labels, probs):\n",
        "    thresholds = []\n",
        "    for i in range(probs.shape[1]):\n",
        "        p, r, t = metrics.precision_recall_curve(labels[:, i], probs[:, i])\n",
        "        f1_scores = np.where((p + r) == 0, 0, 2 * p * r / (p + r)) #防止/0\n",
        "        threshold = t[np.nanargmax(f1_scores)]\n",
        "        thresholds.append(threshold)\n",
        "    thresholds = np.array(thresholds)\n",
        "    print(\"Optimal thresholds at \", thresholds)\n",
        "    return thresholds\n",
        "\n",
        "def predict_for_split(args_dicts, model_paths, split):\n",
        "    loaders = [get_loader_on_split(args_dict, split) for args_dict in args_dicts]\n",
        "    all_model_probs = [get_model_predictions(args_dict, model_path, loader) \\\n",
        "            for args_dict, model_path, loader in zip(args_dicts, model_paths, loaders)]\n",
        "    probs = np.mean(all_model_probs, axis=0)\n",
        "    # labels should be the same across all models\n",
        "    labels = loaders[0].dataset.labels\n",
        "\n",
        "    if 'valid' in split:\n",
        "        thresholds = optimal_threshold_compute(labels, probs)\n",
        "        #print(loaders[0].dataset.pathologies)\n",
        "        auc = metrics.roc_auc_score(labels, probs)\n",
        "        print(\"AUC\", auc)\n",
        "        name = str(auc) + '-' + split\n",
        "    else:\n",
        "        name = split\n",
        "        thresholds = None\n",
        "\n",
        "    return probs, thresholds, name\n",
        "\n",
        "\n",
        "def predict(model_paths, split=\"valid_young\", save=True):\n",
        "\n",
        "    def get_model_params(model_path):\n",
        "        #params = json.load(open(\n",
        "        #    os.path.dirname(model_path) + '/params.txt', 'r'))\n",
        "        params = json.load(open('/content/drive/MyDrive/ML/history_model/CheXneXt_age/young/ep_10/run_dir/params.txt', 'r'))\n",
        "        return params\n",
        "\n",
        "    model_args_dicts = [get_model_params(model_path) for model_path in model_paths]\n",
        "\n",
        "    folder_name = '/content/drive/MyDrive/ML/history_model/CheXneXt_gender/Female/ep_10/predict/female/predictions' + str(int(round(time.time() * 1000)))\n",
        "\n",
        "    probs, thresholds, name = predict_for_split(model_args_dicts, model_paths, split)\n",
        "\n",
        "    if save:\n",
        "        if not os.path.exists(folder_name):\n",
        "            os.makedirs(folder_name)\n",
        "        np.save(folder_name + '/' + name, probs)\n",
        "\n",
        "        try:\n",
        "            loaded_probs = np.load(folder_name + '/' + name + \".npy\", allow_pickle=True)\n",
        "            print(\"Loaded probs shape:\", loaded_probs.shape)\n",
        "        except Exception as e:\n",
        "            print(\"Error loading .npy file:\", e)\n",
        "\n",
        "        print(\"Predictions saved to \", folder_name)\n",
        "\n",
        "        params = {\"model_paths\": model_paths,\n",
        "                  \"num_models\" : len(model_paths)}\n",
        "        with open(folder_name + '/params.json', 'w') as outfile:\n",
        "            json.dump(params, outfile)\n",
        "\n",
        "        return folder_name + '/' + name + \".npy\"\n",
        "\n",
        "    else:\n",
        "\n",
        "        return probs, thresholds\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \"\"\"\n",
        "    Usage\n",
        "        python predict.py model1 model2 ... modelN\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"\n",
        "    parser = util.get_parser()\n",
        "    parser.add_argument(\n",
        "        'model_paths',\n",
        "        nargs='+',\n",
        "        help=\"path to models\")\n",
        "    args = parser.parse_args()\n",
        "    \"\"\"\n",
        "\n",
        "    args = argparse.Namespace(\n",
        "        model_paths=[\"/content/drive/MyDrive/ML/history_model/CheXneXt_age/young/ep_10/run_dir/val0.276692_train0.304059_epoch1\", \"/content/drive/MyDrive/ML/history_model/CheXneXt_age/young/ep_10/run_dir/val0.262023_train0.267144_epoch2\", \"/content/drive/MyDrive/ML/history_model/CheXneXt_age/young/ep_10/run_dir/val0.237520_train0.243476_epoch3\", \"/content/drive/MyDrive/ML/history_model/CheXneXt_age/young/ep_10/run_dir/val0.228785_train0.211695_epoch4\", \"/content/drive/MyDrive/ML/history_model/CheXneXt_age/young/ep_10/run_dir/val0.205620_train0.163654_epoch5\", \"/content/drive/MyDrive/ML/history_model/CheXneXt_age/young/ep_10/run_dir/val0.215539_train0.109086_epoch6\", \"/content/drive/MyDrive/ML/history_model/CheXneXt_age/young/ep_10/run_dir/val0.220947_train0.071413_epoch7\", \"/content/drive/MyDrive/ML/history_model/CheXneXt_age/young/ep_10/run_dir/val0.187284_train0.035033_epoch8\", \"/content/drive/MyDrive/ML/history_model/CheXneXt_age/young/ep_10/run_dir/val0.188101_train0.021869_epoch9\", \"/content/drive/MyDrive/ML/history_model/CheXneXt_age/young/ep_10/run_dir/val0.193619_train0.015704_epoch10\"])\n",
        "    predict(args.model_paths, save=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGqV7VSgrOwn"
      },
      "source": [
        "預測驗證集中每個病例在各病徵的機率"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sewnfbbfNlta",
        "outputId": "e9a6f130-5f96-4646-dbee-ee59460f7fbd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "file_path = '/content/drive/MyDrive/ML/history_model/CheXneXt_age/middle/ep_10/predict/middle/predictions/1732349921323/0.8196511379037413-valid_middle.npy'\n",
        "try:\n",
        "    data = np.load(\"/content/drive/MyDrive/ML/history_model/CheXneXt_age/middle/ep_10/predict/middle/predictions/1732349921323/0.8196511379037413-valid_middle.npy\")\n",
        "    print(data)\n",
        "except Exception as e:\n",
        "    print(\"Error loading .npy file:\", e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIV1Znxhrk3y"
      },
      "source": [
        "預測疾病"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVRN_YWarhXz",
        "outputId": "0b13f5be-b65c-4a06-ea77-22c17832da1a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from torch.autograd import Variable\n",
        "\n",
        "# 定義模型載入函數\n",
        "def load_model(weight_path, num_classes=4):\n",
        "    # 初始化模型時手動提供必要的參數\n",
        "    class Config:\n",
        "        scratch = False\n",
        "        drop_rate = 0.0\n",
        "    config = Config()\n",
        "\n",
        "    model = DenseNet_train(config=config, nclasses=num_classes)  # 使用 Config 提供必要參數\n",
        "    model.load_state_dict(torch.load(weight_path))\n",
        "    model.eval()\n",
        "    model = model.cuda()\n",
        "    return model\n",
        "\n",
        "# 定義影像預處理函數\n",
        "def preprocess_image(image_path, scale=224):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((scale, scale)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    return transform(image).unsqueeze(0)\n",
        "\n",
        "def predict(models, image_paths, thresholds):\n",
        "    \"\"\"\n",
        "    使用多個模型對圖像進行預測，並應用對應病徵的 threshold 進行分類\n",
        "    models: 模型列表\n",
        "    image_paths: 圖像路徑列表\n",
        "    thresholds: 各病徵的 threshold 值 (形狀: [num_classes])\n",
        "    \"\"\"\n",
        "    all_predictions = []\n",
        "    for image_path in image_paths:\n",
        "        image = preprocess_image(image_path).cuda()\n",
        "        predictions = []\n",
        "        for model in models:\n",
        "            with torch.no_grad():\n",
        "                outputs = model(image)\n",
        "                probabilities = torch.sigmoid(outputs).cpu().numpy()\n",
        "                predictions.append(probabilities)\n",
        "        avg_prediction = np.mean(predictions, axis=0)\n",
        "        binary_prediction = (avg_prediction >= thresholds).astype(int)  # 根據 threshold 分類\n",
        "        all_predictions.append(binary_prediction.flatten())\n",
        "    return all_predictions\n",
        "\n",
        "# 定義每個病徵的特定 threshold\n",
        "thresholds = np.array([0.38284844, 0.46058702, 0.4600233, 0.4011343])  # 對應 [Nodule, Infiltration, Effusion, Atelectasis]\n",
        "\n",
        "\n",
        "# 權重檔案路徑\n",
        "weight_paths = [\n",
        "    \"/content/drive/MyDrive/ML/history_model/CheXneXt_age/young/ep_10/run_dir/val0.276692_train0.304059_epoch1\", \"/content/drive/MyDrive/ML/history_model/CheXneXt_age/young/ep_10/run_dir/val0.262023_train0.267144_epoch2\", \"/content/drive/MyDrive/ML/history_model/CheXneXt_age/young/ep_10/run_dir/val0.237520_train0.243476_epoch3\", \"/content/drive/MyDrive/ML/history_model/CheXneXt_age/young/ep_10/run_dir/val0.228785_train0.211695_epoch4\", \"/content/drive/MyDrive/ML/history_model/CheXneXt_age/young/ep_10/run_dir/val0.205620_train0.163654_epoch5\", \"/content/drive/MyDrive/ML/history_model/CheXneXt_age/young/ep_10/run_dir/val0.215539_train0.109086_epoch6\", \"/content/drive/MyDrive/ML/history_model/CheXneXt_age/young/ep_10/run_dir/val0.220947_train0.071413_epoch7\", \"/content/drive/MyDrive/ML/history_model/CheXneXt_age/young/ep_10/run_dir/val0.187284_train0.035033_epoch8\", \"/content/drive/MyDrive/ML/history_model/CheXneXt_age/young/ep_10/run_dir/val0.188101_train0.021869_epoch9\", \"/content/drive/MyDrive/ML/history_model/CheXneXt_age/young/ep_10/run_dir/val0.193619_train0.015704_epoch10\"]\n",
        "\n",
        "# 影像檔案路徑\n",
        "image_paths = [\n",
        "    #A\n",
        "    \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Atelectasis/00000072_000.png\",\n",
        "    \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Atelectasis/00000086_002.png\",\n",
        "    \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Atelectasis/00000119_001.png\",\n",
        "    \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Atelectasis/00000120_000.png\",\n",
        "    \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Atelectasis/00000248_008.png\",\n",
        "    \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Atelectasis/00000307_000.png\",\n",
        "    \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Atelectasis/00000324_015.png\",\n",
        "    \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Atelectasis/00000421_000.png\",\n",
        "    \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Atelectasis/00000963_011.png\",\n",
        "    \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Atelectasis/00001088_008.png\",\n",
        "]\n",
        "\n",
        "# 載入所有模型\n",
        "models = [load_model(weight_path) for weight_path in weight_paths]\n",
        "\n",
        "# 預測並應用 threshold\n",
        "predictions = predict(models, image_paths, thresholds=thresholds)\n",
        "\n",
        "# 提取原始圖片編號作為索引\n",
        "image_ids = [os.path.splitext(os.path.basename(path))[0] for path in image_paths]\n",
        "\n",
        "# 建立表格\n",
        "df = pd.DataFrame(predictions, columns=[\"Nodule\", \"Infiltration\", \"Effusion\", \"Atelectasis\"], index=image_ids)\n",
        "\n",
        "# 輸出結果\n",
        "print(df)\n",
        "\n",
        "# 儲存為 CSV\n",
        "output_path = \"/content/drive/MyDrive/Machine-learning-project/predictions_with_image_ids.csv\"\n",
        "df.to_csv(output_path, index=True)\n",
        "print(f\"Predictions saved to {output_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0B2Fua7namn"
      },
      "source": [
        "**Model_1-ROC**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "id": "Pzw7Q65LOvIK",
        "outputId": "e97c1539-f13f-4196-dc37-dfe9b160346b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "csv_path = '/content/drive/MyDrive/ML/data/valid_F.csv'\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "true_labels = df.iloc[:, 1:].values\n",
        "\n",
        "probs = np.load('/content/drive/MyDrive/ML/history_model/CheXneXt_gender/Female/ep_10/predict/female/predictions/1732374997769/0.8291619762265146-valid_F.npy', allow_pickle=True)\n",
        "\n",
        "class_names = df.columns[1:]\n",
        "\n",
        "def plot_multiclass_roc(true_labels, probs, class_names):\n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    for i in range(len(class_names)):\n",
        "        fpr, tpr, _ = roc_curve(true_labels[:, i], probs[:, i])\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, lw=2, label=f\"{class_names[i]} (AUC = {roc_auc:.2f})\")\n",
        "\n",
        "    #plot total roc curve\n",
        "    #start\n",
        "    fpr, tpr, _ = roc_curve(true_labels.reshape(-1), probs.reshape(-1))\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, lw=2, label=f\"Total (AUC = {roc_auc:.2f})\")\n",
        "    #end\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random (AUC = 0.50)')\n",
        "\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel(\"False Positive Rate (FPR)\")\n",
        "    plt.ylabel(\"True Positive Rate (TPR)\")\n",
        "    plt.title(\"ROC AUC Curves for Train_female Each Symptom in Model_CheXneXt\")\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "plot_multiclass_roc(true_labels, probs, class_names)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1-13Xm8Q9e0"
      },
      "source": [
        "**Model_2-ROC**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "3NNHqaLsQ-sj",
        "outputId": "87151523-88d4-46c2-cd92-f76bc96a6fcc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "csv_path = '/content/drive/MyDrive/ML/data/valid_F.csv'\n",
        "probs_csv_path = '/content/drive/MyDrive/Machine-learning-project/Xception/result/10_Epochs_F_1120_0143/roc_F_pre.csv'\n",
        "\n",
        "df = pd.read_csv(csv_path)\n",
        "true_labels = df.iloc[:, 1:].values\n",
        "class_names = df.columns[1:]\n",
        "\n",
        "probs = pd.read_csv(probs_csv_path).values\n",
        "\n",
        "def plot_multiclass_roc(true_labels, probs, class_names):\n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    for i in range(len(class_names)):\n",
        "        fpr, tpr, _ = roc_curve(true_labels[:, i], probs[:, i])\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, lw=2, label=f\"{class_names[i]} (AUC = {roc_auc:.2f})\")\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(true_labels.ravel(), probs.ravel())\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, lw=2, label=f\"Total (AUC = {roc_auc:.2f})\")\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random (AUC = 0.50)')\n",
        "\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel(\"False Positive Rate (FPR)\")\n",
        "    plt.ylabel(\"True Positive Rate (TPR)\")\n",
        "    plt.title(\"ROC AUC Curves for Train_female Each Symptom in Model_Xception\")\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "plot_multiclass_roc(true_labels, probs, class_names)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VP4Ruc3TmdL"
      },
      "source": [
        "10 條 ROC 曲線，分別對應 5 個客群的 Xception 模型 和 CheXneXt 模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "pUPx6Yw4TnLE",
        "outputId": "cb19dd68-fa5a-47a4-b636-997320839cce"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# 路徑設定\n",
        "data_paths = {\n",
        "    \"Female\": {\n",
        "        \"true_csv\": \"/content/drive/MyDrive/ML/data/valid_F.csv\",\n",
        "        \"chexnext_probs\": \"/content/drive/MyDrive/ML/history_model/CheXneXt_gender/Female/ep_10/predict/female/predictions/1732374997769/0.8291619762265146-valid_F.npy\",\n",
        "        \"xception_probs\": \"/content/drive/MyDrive/Machine-learning-project/Xception/result/10_Epochs_F_1120_0143/roc_F_pre.csv\"\n",
        "    },\n",
        "    \"Male\": {\n",
        "        \"true_csv\": \"/content/drive/MyDrive/ML/data/valid_M.csv\",\n",
        "        \"chexnext_probs\": \"/content/drive/MyDrive/ML/history_model/CheXneXt_gender/Male/ep_10/predict/male/predictions/1732380203052/0.8276335029453044-valid_M.npy\",\n",
        "        \"xception_probs\": \"/content/drive/MyDrive/Machine-learning-project/Xception/result/10_Epochs_M_1119_2327/roc_M_pre.csv\"\n",
        "    },\n",
        "    \"Young\": {\n",
        "        \"true_csv\": \"/content/drive/MyDrive/ML/data/valid_young.csv\",\n",
        "        \"chexnext_probs\": \"/content/drive/MyDrive/ML/history_model/CheXneXt_age/young/ep_10/predict/young/predictions/1732372765129/0.927858775074568-valid_young.npy\",\n",
        "        \"xception_probs\": \"/content/drive/MyDrive/Machine-learning-project/Xception/result/10_Epochs_young__1122_1701/roc_young_pre.csv\"\n",
        "    },\n",
        "    \"Middle\": {\n",
        "        \"true_csv\": \"/content/drive/MyDrive/ML/data/valid_middle.csv\",\n",
        "        \"chexnext_probs\": \"/content/drive/MyDrive/ML/history_model/CheXneXt_age/middle/ep_10/predict/middle/predictions/1732349921323/0.8196511379037413-valid_middle.npy\",\n",
        "        \"xception_probs\": \"/content/drive/MyDrive/Machine-learning-project/Xception/result/10_Epochs_middle__1122_2205/roc_middle_pre.csv\"\n",
        "    },\n",
        "    \"Old\": {\n",
        "        \"true_csv\": \"/content/drive/MyDrive/ML/data/valid_old.csv\",\n",
        "        \"chexnext_probs\": \"/content/drive/MyDrive/ML/history_model/CheXneXt_age/old/ep_10/predict/old/predictions/1732285693842/0.8736757582492061-valid_old.npy\",\n",
        "        \"xception_probs\": \"/content/drive/MyDrive/Machine-learning-project/Xception/result/10_Epochs_old__1123_0057/roc_old_pre.csv\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# 繪製多模型 ROC 曲線\n",
        "def plot_10_model_roc(data_paths):\n",
        "    plt.figure(figsize=(12, 10))\n",
        "\n",
        "    # 顏色設定\n",
        "    colors = {\n",
        "        \"Female\": \"blue\",\n",
        "        \"Male\": \"green\",\n",
        "        \"Young\": \"orange\",\n",
        "        \"Middle\": \"purple\",\n",
        "        \"Old\": \"red\"\n",
        "    }\n",
        "\n",
        "    for group, paths in data_paths.items():\n",
        "        # 讀取真實標籤\n",
        "        df = pd.read_csv(paths[\"true_csv\"])\n",
        "        true_labels = df.iloc[:, 1:].values\n",
        "\n",
        "        # 讀取 CheXneXt 預測值\n",
        "        chexnext_probs = np.load(paths[\"chexnext_probs\"], allow_pickle=True)\n",
        "\n",
        "        # 讀取 Xception 預測值\n",
        "        xception_probs = pd.read_csv(paths[\"xception_probs\"]).values\n",
        "\n",
        "        # 繪製 CheXneXt 的總 ROC 曲線（實線）\n",
        "        fpr, tpr, _ = roc_curve(true_labels.ravel(), chexnext_probs.ravel())\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, lw=2, linestyle='-', color=colors[group], label=f\"CheXneXt {group} (AUC = {roc_auc:.2f})\")\n",
        "\n",
        "        # 繪製 Xception 的總 ROC 曲線（虛線）\n",
        "        fpr, tpr, _ = roc_curve(true_labels.ravel(), xception_probs.ravel())\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, lw=2, linestyle='--', color=colors[group], label=f\"Xception {group} (AUC = {roc_auc:.2f})\")\n",
        "\n",
        "    # 添加圖例與參考線\n",
        "    plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random (AUC = 0.50)')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel(\"False Positive Rate (FPR)\")\n",
        "    plt.ylabel(\"True Positive Rate (TPR)\")\n",
        "    plt.title(\"TOTAL ROC AUC for CheXneXt and Xception Across Groups\")\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "# 繪製曲線\n",
        "plot_10_model_roc(data_paths)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-ilKCI0eQKf"
      },
      "source": [
        "10個model的全預測線(每張圖5條)_Model1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "id": "OMukxjGwePl3",
        "outputId": "277d9890-12c5-4987-a2de-b9f86a6d3ca8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "groups = {\n",
        "    \"Female\": {\n",
        "        \"csv_path\": \"/content/drive/MyDrive/ML/data/valid_F.csv\",\n",
        "        \"npy_path\": \"/content/drive/MyDrive/ML/history_model/CheXneXt_gender/Male/ep_10/predict/female/predictions/1732379111661/0.7556504091210221-valid_F.npy\",\n",
        "    },\n",
        "    \"Male\": {\n",
        "        \"csv_path\": \"/content/drive/MyDrive/ML/data/valid_M.csv\",\n",
        "        \"npy_path\": \"/content/drive/MyDrive/ML/history_model/CheXneXt_gender/Male/ep_10/predict/male/predictions/1732380203052/0.8276335029453044-valid_M.npy\",\n",
        "    },\n",
        "    \"Middle\": {\n",
        "        \"csv_path\": \"/content/drive/MyDrive/ML/data/valid_middle.csv\",\n",
        "        \"npy_path\": \"/content/drive/MyDrive/ML/history_model/CheXneXt_gender/Male/ep_10/predict/middle/predictions/1732381048158/0.7938877349467963-valid_middle.npy\",\n",
        "    },\n",
        "    \"Old\": {\n",
        "        \"csv_path\": \"/content/drive/MyDrive/ML/data/valid_old.csv\",\n",
        "        \"npy_path\": \"/content/drive/MyDrive/ML/history_model/CheXneXt_gender/Male/ep_10/predict/old/predictions/1732382123865/0.7663979892214088-valid_old.npy\",\n",
        "    },\n",
        "    \"Young\": {\n",
        "        \"csv_path\": \"/content/drive/MyDrive/ML/data/valid_young.csv\",\n",
        "        \"npy_path\": \"/content/drive/MyDrive/ML/history_model/CheXneXt_gender/Male/ep_10/predict/young/predictions/1732382952584/0.805614894052909-valid_young.npy\",\n",
        "    },\n",
        "}\n",
        "\n",
        "def plot_total_roc(groups):\n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    for group_name, paths in groups.items():\n",
        "        df = pd.read_csv(paths[\"csv_path\"])\n",
        "        true_labels = df.iloc[:, 1:].values\n",
        "        probs = np.load(paths[\"npy_path\"], allow_pickle=True)\n",
        "\n",
        "        fpr, tpr, _ = roc_curve(true_labels.ravel(), probs.ravel())\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        plt.plot(fpr, tpr, lw=2, label=f\"{group_name} (AUC = {roc_auc:.2f})\")\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random (AUC = 0.50)')\n",
        "\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel(\"False Positive Rate (FPR)\")\n",
        "    plt.ylabel(\"True Positive Rate (TPR)\")\n",
        "    plt.title(\"Total ROC AUC Curves for Train_male Groups\")\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "plot_total_roc(groups)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2gybhqEoBcg"
      },
      "source": [
        "10個model的全預測線(每張圖5條)_Model2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "id": "r2y1ATwsoCTg",
        "outputId": "f0c39d36-e090-4dc7-f0de-a28b0f64617a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "groups = {\n",
        "    \"Female\": {\n",
        "        \"true_csv_path\": \"/content/drive/MyDrive/ML/data/valid_F.csv\",\n",
        "        \"start_column\": 6,\n",
        "    },\n",
        "    \"Male\": {\n",
        "        \"true_csv_path\": \"/content/drive/MyDrive/ML/data/valid_M.csv\",\n",
        "        \"start_column\": 1,\n",
        "    },\n",
        "    \"Middle\": {\n",
        "        \"true_csv_path\": \"/content/drive/MyDrive/ML/data/valid_middle.csv\",\n",
        "        \"start_column\": 16,\n",
        "    },\n",
        "    \"Old\": {\n",
        "        \"true_csv_path\": \"/content/drive/MyDrive/ML/data/valid_old.csv\",\n",
        "        \"start_column\": 21,\n",
        "    },\n",
        "    \"Young\": {\n",
        "        \"true_csv_path\": \"/content/drive/MyDrive/ML/data/valid_young.csv\",\n",
        "        \"start_column\": 11,\n",
        "    },\n",
        "}\n",
        "\n",
        "prediction_csv_path = \"/content/drive/MyDrive/Machine-learning-project/Xception/1122_result/F/F_prediction.csv\"\n",
        "\n",
        "def plot_total_roc(groups, prediction_csv_path):\n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    pred_data = pd.read_csv(prediction_csv_path, skiprows=1)\n",
        "\n",
        "    for group_name, paths in groups.items():\n",
        "        true_data = pd.read_csv(paths[\"true_csv_path\"])\n",
        "        true_labels = true_data.iloc[:, 1:].values\n",
        "\n",
        "        start_col = paths[\"start_column\"]\n",
        "        pred_probs = pred_data.iloc[:, start_col : start_col + 4].values\n",
        "\n",
        "        min_samples = min(true_labels.shape[0], pred_probs.shape[0])\n",
        "        true_labels = true_labels[:min_samples, :]\n",
        "        pred_probs = pred_probs[:min_samples, :]\n",
        "\n",
        "        fpr, tpr, _ = roc_curve(true_labels.ravel(), pred_probs.ravel())\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        plt.plot(fpr, tpr, lw=2, label=f\"{group_name} (AUC = {roc_auc:.2f})\")\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random (AUC = 0.50)')\n",
        "\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel(\"False Positive Rate (FPR)\")\n",
        "    plt.ylabel(\"True Positive Rate (TPR)\")\n",
        "    plt.title(\"Total ROC AUC Curves for Train_female Groups\")\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "plot_total_roc(groups, prediction_csv_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeD8i9WjsZa4"
      },
      "source": [
        "10個model的全預測線(每張圖5條)_Model2_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "id": "R--B-spZsZHh",
        "outputId": "24bd096d-9601-4e1a-d0b3-082c091cfe52"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "groups = {\n",
        "    \"Female\": {\n",
        "        \"true_csv_path\": \"/content/drive/MyDrive/ML/data/valid_F.csv\",\n",
        "        \"pred_csv_path\": \"/content/drive/MyDrive/Machine-learning-project/Xception/result/10_Epochs_old__1123_0057/roc_F_pre.csv\",\n",
        "    },\n",
        "    \"Male\": {\n",
        "        \"true_csv_path\": \"/content/drive/MyDrive/ML/data/valid_M.csv\",\n",
        "        \"pred_csv_path\": \"/content/drive/MyDrive/Machine-learning-project/Xception/result/10_Epochs_old__1123_0057/roc_M_pre.csv\",\n",
        "    },\n",
        "    \"Middle\": {\n",
        "        \"true_csv_path\": \"/content/drive/MyDrive/ML/data/valid_middle.csv\",\n",
        "        \"pred_csv_path\": \"/content/drive/MyDrive/Machine-learning-project/Xception/result/10_Epochs_old__1123_0057/roc_middle_pre.csv\",\n",
        "    },\n",
        "    \"Old\": {\n",
        "        \"true_csv_path\": \"/content/drive/MyDrive/ML/data/valid_old.csv\",\n",
        "        \"pred_csv_path\": \"/content/drive/MyDrive/Machine-learning-project/Xception/result/10_Epochs_old__1123_0057/roc_old_pre.csv\",\n",
        "    },\n",
        "    \"Young\": {\n",
        "        \"true_csv_path\": \"/content/drive/MyDrive/ML/data/valid_young.csv\",\n",
        "        \"pred_csv_path\": \"/content/drive/MyDrive/Machine-learning-project/Xception/result/10_Epochs_old__1123_0057/roc_young_pre.csv\",\n",
        "    },\n",
        "}\n",
        "\n",
        "def plot_total_roc(groups):\n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    for group_name, paths in groups.items():\n",
        "        true_data = pd.read_csv(paths[\"true_csv_path\"])\n",
        "        true_labels = true_data.iloc[:, 1:].values\n",
        "\n",
        "        pred_data = pd.read_csv(paths[\"pred_csv_path\"], skiprows=0)\n",
        "        pred_probs = pred_data.values\n",
        "\n",
        "        min_samples = min(true_labels.shape[0], pred_probs.shape[0])\n",
        "        true_labels = true_labels[:min_samples, :]\n",
        "        pred_probs = pred_probs[:min_samples, :]\n",
        "\n",
        "        fpr, tpr, _ = roc_curve(true_labels.ravel(), pred_probs.ravel())\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        plt.plot(fpr, tpr, lw=2, label=f\"{group_name} (AUC = {roc_auc:.2f})\")\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random (AUC = 0.50)')\n",
        "\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel(\"False Positive Rate (FPR)\")\n",
        "    plt.ylabel(\"True Positive Rate (TPR)\")\n",
        "    plt.title(\"Total ROC AUC Curves for Train_old Groups\")\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "plot_total_roc(groups)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyRDFUkMwqtT"
      },
      "source": [
        "同客群不同model的比較(5張圖)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "dgvD4cAxw0Ii",
        "outputId": "6bd2655d-b0fc-44b7-ce4e-7d87fddacc7d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "csv_path = '/content/drive/MyDrive/ML/data/valid_F.csv'\n",
        "chexnext_probs_path = '/content/drive/MyDrive/ML/history_model/CheXneXt_gender/Female/ep_10/predict/female/predictions/1732374997769/0.8291619762265146-valid_F.npy'\n",
        "xception_probs_path = '/content/drive/MyDrive/Machine-learning-project/Xception/result/10_Epochs_F_1120_0143/roc_F_pre.csv'\n",
        "\n",
        "df = pd.read_csv(csv_path)\n",
        "true_labels = df.iloc[:, 1:].values\n",
        "class_names = df.columns[1:]\n",
        "\n",
        "chexnext_probs = np.load(chexnext_probs_path, allow_pickle=True)\n",
        "xception_probs = pd.read_csv(xception_probs_path).values\n",
        "\n",
        "def plot_multiclass_roc(true_labels, chexnext_probs, xception_probs, class_names):\n",
        "    plt.figure(figsize=(12, 10))\n",
        "\n",
        "    for i in range(len(class_names)):\n",
        "        fpr, tpr, _ = roc_curve(true_labels[:, i], chexnext_probs[:, i])\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, lw=2, linestyle='--', label=f\"CheXneXt {class_names[i]} (AUC = {roc_auc:.2f})\")\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(true_labels.ravel(), chexnext_probs.ravel())\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, lw=3, linestyle='-', label=f\"CheXneXt Total (AUC = {roc_auc:.2f})\")\n",
        "\n",
        "    for i in range(len(class_names)):\n",
        "        fpr, tpr, _ = roc_curve(true_labels[:, i], xception_probs[:, i])\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, lw=2, linestyle='--', label=f\"Xception {class_names[i]} (AUC = {roc_auc:.2f})\")\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(true_labels.ravel(), xception_probs.ravel())\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, lw=3, linestyle='-', label=f\"Xception Total (AUC = {roc_auc:.2f})\")\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random (AUC = 0.50)')\n",
        "\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel(\"False Positive Rate (FPR)\")\n",
        "    plt.ylabel(\"True Positive Rate (TPR)\")\n",
        "    plt.title(\"ROC AUC Curves for CheXneXt and Xception in female_Group\")\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "plot_multiclass_roc(true_labels, chexnext_probs, xception_probs, class_names)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1x-b-Jy7tl5"
      },
      "source": [
        "同Model_1不同客群的比較"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "id": "il2rA_zB7xx0",
        "outputId": "d9f3f58d-ff30-4d21-8229-99a385b7bfa9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "groups = {\n",
        "    \"Female\": {\n",
        "        \"csv_path\": \"/content/drive/MyDrive/ML/data/valid_F.csv\",\n",
        "        \"npy_path\": \"/content/drive/MyDrive/ML/history_model/CheXneXt_gender/Female/ep_10/predict/female/predictions/1732374997769/0.8291619762265146-valid_F.npy\",\n",
        "    },\n",
        "    \"Male\": {\n",
        "        \"csv_path\": \"/content/drive/MyDrive/ML/data/valid_M.csv\",\n",
        "        \"npy_path\": \"/content/drive/MyDrive/ML/history_model/CheXneXt_gender/Male/ep_10/predict/male/predictions/1732380203052/0.8276335029453044-valid_M.npy\",\n",
        "    },\n",
        "    \"Middle\": {\n",
        "        \"csv_path\": \"/content/drive/MyDrive/ML/data/valid_middle.csv\",\n",
        "        \"npy_path\": \"/content/drive/MyDrive/ML/history_model/CheXneXt_age/middle/ep_10/predict/middle/predictions/1732349921323/0.8196511379037413-valid_middle.npy\",\n",
        "    },\n",
        "    \"Old\": {\n",
        "        \"csv_path\": \"/content/drive/MyDrive/ML/data/valid_old.csv\",\n",
        "        \"npy_path\": \"/content/drive/MyDrive/ML/history_model/CheXneXt_age/old/ep_10/predict/old/predictions/1732285693842/0.8736757582492061-valid_old.npy\",\n",
        "    },\n",
        "    \"Young\": {\n",
        "        \"csv_path\": \"/content/drive/MyDrive/ML/data/valid_young.csv\",\n",
        "        \"npy_path\": \"/content/drive/MyDrive/ML/history_model/CheXneXt_age/young/ep_10/predict/young/predictions/1732372765129/0.927858775074568-valid_young.npy\",\n",
        "    },\n",
        "}\n",
        "\n",
        "def plot_total_roc(groups):\n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    for group_name, paths in groups.items():\n",
        "        df = pd.read_csv(paths[\"csv_path\"])\n",
        "        true_labels = df.iloc[:, 1:].values\n",
        "        probs = np.load(paths[\"npy_path\"], allow_pickle=True)\n",
        "\n",
        "        fpr, tpr, _ = roc_curve(true_labels.ravel(), probs.ravel())\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        plt.plot(fpr, tpr, lw=2, label=f\"{group_name} (AUC = {roc_auc:.2f})\")\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random (AUC = 0.50)')\n",
        "\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel(\"False Positive Rate (FPR)\")\n",
        "    plt.ylabel(\"True Positive Rate (TPR)\")\n",
        "    plt.title(\"Total ROC AUC Curves for Xception each Groups\")\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "plot_total_roc(groups)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBh4Rzo2_aJh"
      },
      "source": [
        "同Model_2不同客群的比較"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "id": "BZu1Dd5o_bU7",
        "outputId": "88bc4598-a0b5-41c8-9f49-5596bf991e36"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "groups = {\n",
        "    \"Female\": {\n",
        "        \"true_csv_path\": \"/content/drive/MyDrive/ML/data/valid_F.csv\",\n",
        "        \"pred_csv_path\": \"/content/drive/MyDrive/Machine-learning-project/Xception/result/10_Epochs_F_1120_0143/roc_F_pre.csv\",\n",
        "    },\n",
        "    \"Male\": {\n",
        "        \"true_csv_path\": \"/content/drive/MyDrive/ML/data/valid_M.csv\",\n",
        "        \"pred_csv_path\": \"/content/drive/MyDrive/Machine-learning-project/Xception/result/10_Epochs_M_1119_2327/roc_M_pre.csv\",\n",
        "    },\n",
        "    \"Middle\": {\n",
        "        \"true_csv_path\": \"/content/drive/MyDrive/ML/data/valid_middle.csv\",\n",
        "        \"pred_csv_path\": \"/content/drive/MyDrive/Machine-learning-project/Xception/result/10_Epochs_middle__1122_2205/roc_middle_pre.csv\",\n",
        "    },\n",
        "    \"Old\": {\n",
        "        \"true_csv_path\": \"/content/drive/MyDrive/ML/data/valid_old.csv\",\n",
        "        \"pred_csv_path\": \"/content/drive/MyDrive/Machine-learning-project/Xception/result/10_Epochs_old__1123_0057/roc_old_pre.csv\",\n",
        "    },\n",
        "    \"Young\": {\n",
        "        \"true_csv_path\": \"/content/drive/MyDrive/ML/data/valid_young.csv\",\n",
        "        \"pred_csv_path\": \"/content/drive/MyDrive/Machine-learning-project/Xception/result/10_Epochs_young__1122_1701/roc_young_pre.csv\",\n",
        "    },\n",
        "}\n",
        "\n",
        "def plot_total_roc(groups):\n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    for group_name, paths in groups.items():\n",
        "        true_data = pd.read_csv(paths[\"true_csv_path\"])\n",
        "        true_labels = true_data.iloc[:, 1:].values\n",
        "\n",
        "        pred_data = pd.read_csv(paths[\"pred_csv_path\"], skiprows=0)\n",
        "        pred_probs = pred_data.values\n",
        "\n",
        "        min_samples = min(true_labels.shape[0], pred_probs.shape[0])\n",
        "        true_labels = true_labels[:min_samples, :]\n",
        "        pred_probs = pred_probs[:min_samples, :]\n",
        "\n",
        "        fpr, tpr, _ = roc_curve(true_labels.ravel(), pred_probs.ravel())\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        plt.plot(fpr, tpr, lw=2, label=f\"{group_name} (AUC = {roc_auc:.2f})\")\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random (AUC = 0.50)')\n",
        "\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel(\"False Positive Rate (FPR)\")\n",
        "    plt.ylabel(\"True Positive Rate (TPR)\")\n",
        "    plt.title(\"Total ROC AUC Curves for Xception each Groups\")\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "plot_total_roc(groups)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbdgN0LfK9tM"
      },
      "source": [
        "對於不同種客群兩個model在四個病徵中的比較"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "qywIlxK5LBVb",
        "outputId": "6ec78e69-e54a-4cdf-dfd2-21ef4916a8bc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "data_paths = {\n",
        "    \"Female\": {\n",
        "        \"true_csv\": \"/content/drive/MyDrive/ML/data/valid_F.csv\",\n",
        "        \"chexnext_probs\": \"/content/drive/MyDrive/ML/history_model/CheXneXt_gender/Female/ep_10/predict/female/predictions/1732374997769/0.8291619762265146-valid_F.npy\",\n",
        "        \"xception_probs\": \"/content/drive/MyDrive/Machine-learning-project/Xception/result/10_Epochs_F_1120_0143/roc_F_pre.csv\"\n",
        "    },\n",
        "    \"Male\": {\n",
        "        \"true_csv\": \"/content/drive/MyDrive/ML/data/valid_M.csv\",\n",
        "        \"chexnext_probs\": \"/content/drive/MyDrive/ML/history_model/CheXneXt_gender/Male/ep_10/predict/male/predictions/1732380203052/0.8276335029453044-valid_M.npy\",\n",
        "        \"xception_probs\": \"/content/drive/MyDrive/Machine-learning-project/Xception/result/10_Epochs_M_1119_2327/roc_M_pre.csv\"\n",
        "    },\n",
        "    \"Young\": {\n",
        "        \"true_csv\": \"/content/drive/MyDrive/ML/data/valid_young.csv\",\n",
        "        \"chexnext_probs\": \"/content/drive/MyDrive/ML/history_model/CheXneXt_age/young/ep_10/predict/young/predictions/1732372765129/0.927858775074568-valid_young.npy\",\n",
        "        \"xception_probs\": \"/content/drive/MyDrive/Machine-learning-project/Xception/result/10_Epochs_young__1122_1701/roc_young_pre.csv\"\n",
        "    },\n",
        "    \"Middle\": {\n",
        "        \"true_csv\": \"/content/drive/MyDrive/ML/data/valid_middle.csv\",\n",
        "        \"chexnext_probs\": \"/content/drive/MyDrive/ML/history_model/CheXneXt_age/middle/ep_10/predict/middle/predictions/1732349921323/0.8196511379037413-valid_middle.npy\",\n",
        "        \"xception_probs\": \"/content/drive/MyDrive/Machine-learning-project/Xception/result/10_Epochs_middle__1122_2205/roc_middle_pre.csv\"\n",
        "    },\n",
        "    \"Old\": {\n",
        "        \"true_csv\": \"/content/drive/MyDrive/ML/data/valid_old.csv\",\n",
        "        \"chexnext_probs\": \"/content/drive/MyDrive/ML/history_model/CheXneXt_age/old/ep_10/predict/old/predictions/1732285693842/0.8736757582492061-valid_old.npy\",\n",
        "        \"xception_probs\": \"/content/drive/MyDrive/Machine-learning-project/Xception/result/10_Epochs_old__1123_0057/roc_old_pre.csv\"\n",
        "    }\n",
        "}\n",
        "\n",
        "def plot_nodule_roc(data_paths):\n",
        "    plt.figure(figsize=(12, 10))\n",
        "\n",
        "    colors = {\n",
        "        \"Female\": \"blue\",\n",
        "        \"Male\": \"green\",\n",
        "        \"Young\": \"orange\",\n",
        "        \"Middle\": \"purple\",\n",
        "        \"Old\": \"red\"\n",
        "    }\n",
        "\n",
        "    for group, paths in data_paths.items():\n",
        "        df = pd.read_csv(paths[\"true_csv\"])\n",
        "        true_labels = df.iloc[:, 1:].values\n",
        "\n",
        "        chexnext_probs = np.load(paths[\"chexnext_probs\"], allow_pickle=True)\n",
        "        xception_probs = pd.read_csv(paths[\"xception_probs\"]).values\n",
        "\n",
        "        fpr, tpr, _ = roc_curve(true_labels[:, 3], chexnext_probs[:, 3])\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, lw=2, linestyle='-', color=colors[group], label=f\"CheXneXt {group} (AUC = {roc_auc:.2f})\")\n",
        "        fpr, tpr, _ = roc_curve(true_labels[:, 3], xception_probs[:, 3])\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, lw=2, linestyle='--', color=colors[group], label=f\"Xception {group} (AUC = {roc_auc:.2f})\")\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random (AUC = 0.50)')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel(\"False Positive Rate (FPR)\")\n",
        "    plt.ylabel(\"True Positive Rate (TPR)\")\n",
        "    plt.title(\"Atelectasis ROC AUC for CheXneXt and Xception\")\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "plot_nodule_roc(data_paths)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hyq7JnaA1DJA"
      },
      "source": [
        "**grad cam**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMX7uQbyA1Rl",
        "outputId": "24321529-a437-401f-db32-5d94c999e45d"
      },
      "outputs": [],
      "source": [
        "! pip install grad-cam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BRWdF04l1RDA",
        "outputId": "2f984b3c-be59-4702-c5d3-6a1e968d16d0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from torchvision.models import densenet121\n",
        "from torchvision.transforms import transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def preprocess_image(image_path, target_size=(224, 224)):\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize(target_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    return preprocess(image).unsqueeze(0)\n",
        "\n",
        "def generate_grad_cam_pytorch(model, image_tensor, target_layer):\n",
        "    model.eval()\n",
        "    activations = []\n",
        "    gradients = []\n",
        "\n",
        "    def forward_hook(module, input, output):\n",
        "        activations.append(output)\n",
        "\n",
        "    def backward_hook(module, grad_in, grad_out):\n",
        "        gradients.append(grad_out[0])\n",
        "\n",
        "    handle_forward = target_layer.register_forward_hook(forward_hook)\n",
        "    handle_backward = target_layer.register_backward_hook(backward_hook)\n",
        "\n",
        "    output = model(image_tensor)\n",
        "    target_class = torch.argmax(output, dim=1)\n",
        "    loss = output[:, target_class]\n",
        "\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    gradient = gradients[0].cpu().data.numpy()\n",
        "    activation = activations[0].cpu().data.numpy()\n",
        "\n",
        "    weights = np.mean(gradient, axis=(2, 3))\n",
        "    cam = np.zeros(activation.shape[2:], dtype=np.float32)\n",
        "\n",
        "    for i, w in enumerate(weights[0]):\n",
        "        cam += w * activation[0, i, :, :]\n",
        "\n",
        "    cam = np.maximum(cam, 0)\n",
        "    cam = cam / np.max(cam)\n",
        "    cam = np.uint8(255 * cam)\n",
        "\n",
        "    handle_forward.remove()\n",
        "    handle_backward.remove()\n",
        "\n",
        "    return cam\n",
        "\n",
        "def overlay_grad_cam_high_res(image_path, heatmap, alpha=0.4):\n",
        "    original_img = Image.open(image_path).convert(\"RGB\")\n",
        "    original_size = original_img.size\n",
        "\n",
        "    heatmap_resized = Image.fromarray(heatmap).resize(original_size, Image.BILINEAR)\n",
        "    heatmap_resized = np.array(heatmap_resized)\n",
        "\n",
        "    heatmap_color = plt.cm.jet(heatmap_resized / 255.0)[:, :, :3]\n",
        "    heatmap_color = (heatmap_color * 255).astype(np.uint8)\n",
        "\n",
        "    overlay = np.array(original_img) / 255.0\n",
        "    overlay = (1 - alpha) * overlay + alpha * (heatmap_color / 255.0)\n",
        "    overlay = (overlay * 255).astype(np.uint8)\n",
        "\n",
        "    return overlay\n",
        "\n",
        "def process_and_save_grad_cam(model, image_path, target_layer, save_path):\n",
        "    image_tensor = preprocess_image(image_path)\n",
        "    heatmap = generate_grad_cam_pytorch(model, image_tensor, target_layer)\n",
        "    overlay = overlay_grad_cam_high_res(image_path, heatmap)\n",
        "\n",
        "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "    Image.fromarray(overlay).save(save_path)\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(overlay)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"High-Resolution Grad-CAM Overlay\")\n",
        "    plt.show()\n",
        "\n",
        "model_paths = [\n",
        "    \"/content/drive/MyDrive/ML/history_model/CheXneXt_gender/Male/ep_10/run_dir/val0.315201_train0.347674_epoch1\",\n",
        "    \"/content/drive/MyDrive/ML/history_model/CheXneXt_gender/Male/ep_10/run_dir/val0.305339_train0.308090_epoch2\",\n",
        "    \"/content/drive/MyDrive/ML/history_model/CheXneXt_gender/Male/ep_10/run_dir/val0.306597_train0.281822_epoch3\",\n",
        "    \"/content/drive/MyDrive/ML/history_model/CheXneXt_gender/Male/ep_10/run_dir/val0.316875_train0.245489_epoch4\",\n",
        "    \"/content/drive/MyDrive/ML/history_model/CheXneXt_gender/Male/ep_10/run_dir/val0.300346_train0.157751_epoch5\",\n",
        "    \"/content/drive/MyDrive/ML/history_model/CheXneXt_gender/Male/ep_10/run_dir/val0.312949_train0.113909_epoch6\",\n",
        "    \"/content/drive/MyDrive/ML/history_model/CheXneXt_gender/Male/ep_10/run_dir/val0.329378_train0.086568_epoch7\",\n",
        "    \"/content/drive/MyDrive/ML/history_model/CheXneXt_gender/Male/ep_10/run_dir/val0.329106_train0.066263_epoch8\"\n",
        "]\n",
        "\n",
        "image_paths = {\n",
        "    \"Atelectasis\": [\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Atelectasis/00000072_000.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Atelectasis/00000086_002.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Atelectasis/00000119_001.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Atelectasis/00000120_000.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Atelectasis/00000248_008.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Atelectasis/00000307_000.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Atelectasis/00000324_015.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Atelectasis/00000421_000.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Atelectasis/00000963_011.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Atelectasis/00001088_008.png\",\n",
        "    ],\n",
        "    \"Effusion\": [\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Effusion/00000041_006.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Effusion/00000071_007.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Effusion/00000116_008.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Effusion/00000116_011.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Effusion/00000127_004.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Effusion/00000250_008.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Effusion/00000506_012.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Effusion/00000572_001.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Effusion/00000591_014.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Effusion/00000848_000.png\",\n",
        "    ],\n",
        "    \"Healthy\": [\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Healthy/00000049_002.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Healthy/00000547_007.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Healthy/00000627_001.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Healthy/00000646_007.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Healthy/00000652_018.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Healthy/00000756_005.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Healthy/00000820_020.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Healthy/00000857_001.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Healthy/00000980_004.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Healthy/00001027_001.png\",\n",
        "    ],\n",
        "    \"Infiltration\": [\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Infiltration/00000125_000.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Infiltration/00000181_009.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Infiltration/00000376_010.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Infiltration/00000506_003.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Infiltration/00000548_001.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Infiltration/00000652_012.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Infiltration/00000796_009.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Infiltration/00000873_000.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Infiltration/00001001_002.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Infiltration/00001075_005.png\",\n",
        "    ],\n",
        "    \"Nodule\": [\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Nodule/00000105_004.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Nodule/00000157_000.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Nodule/00000250_003.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Nodule/00000336_000.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Nodule/00000415_000.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Nodule/00000459_017.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Nodule/00000634_004.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Nodule/00000640_001.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Nodule/00000744_001.png\",\n",
        "        \"/content/drive/MyDrive/Machine-learning-project/Xception/image/Nodule/00001012_000.png\",\n",
        "    ],\n",
        "}\n",
        "\n",
        "save_dirs = {\n",
        "    \"Atelectasis\": \"/content/drive/MyDrive/Machine-learning-project/Xception/image/grad_cam_output_model1/M/Atelectasis\",\n",
        "    \"Effusion\": \"/content/drive/MyDrive/Machine-learning-project/Xception/image/grad_cam_output_model1/M/Effusion\",\n",
        "    \"Healthy\": \"/content/drive/MyDrive/Machine-learning-project/Xception/image/grad_cam_output_model1/M/Healthy\",\n",
        "    \"Infiltration\": \"/content/drive/MyDrive/Machine-learning-project/Xception/image/grad_cam_output_model1/M/Infiltration\",\n",
        "    \"Nodule\": \"/content/drive/MyDrive/Machine-learning-project/Xception/image/grad_cam_output_model1/M/Nodule\",\n",
        "}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model = densenet121(pretrained=True)\n",
        "    target_layer = model.features.denseblock4.denselayer16.conv2\n",
        "\n",
        "    for class_name, img_list in image_paths.items():\n",
        "        save_dir = save_dirs[class_name]\n",
        "        for img_path in img_list:\n",
        "            output_save_path = os.path.join(save_dir, os.path.basename(img_path))\n",
        "            process_and_save_grad_cam(model, img_path, target_layer, output_save_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWuHwraVA6rs"
      },
      "source": [
        "**Confusion matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YKb5lmTmA6aF",
        "outputId": "f1730004-7fd8-42e3-ab56-2295bf327886"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "csv_path = '/content/drive/MyDrive/ML/data/valid_young.csv'\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "true_labels = df.iloc[:, 1:].values\n",
        "\n",
        "probs = np.load('/content/drive/MyDrive/ML/history_model/CheXneXt_age/young/ep_10/predict/young/predictions/1732372765129/0.927858775074568-valid_young.npy', allow_pickle=True)\n",
        "\n",
        "class_names = df.columns[1:]\n",
        "\n",
        "threshold_F = [0.18225671, 0.354695, 0.39824185, 0.3147227]\n",
        "threshold_M = [0.16655189, 0.34565434, 0.31126136, 0.2879935]\n",
        "threshold_young = [0.38284844, 0.46058702, 0.4600233, 0.4011343]\n",
        "threshold_middle = [0.15721625, 0.23821387, 0.3097358, 0.30881613]\n",
        "threshold_old = [0.32799268, 0.3056149, 0.42771035, 0.43798673]\n",
        "\n",
        "def plot_confusion_matrix(true_labels, probs, class_names, threshold):\n",
        "    #plt.figure(figsize=(10, 8))\n",
        "    pred = np.zeros(probs.shape)\n",
        "    con_mat = np.zeros((len(class_names), 4))\n",
        "\n",
        "    for i in range(len(class_names)):\n",
        "        for j in range(probs[:, i].shape[0]):\n",
        "          if probs[j, i] >= threshold[i]:\n",
        "            pred[j, i] = 1\n",
        "          else:\n",
        "            pred[j, i] = 0\n",
        "\n",
        "        cm = confusion_matrix(true_labels[:, i], pred[:, i])\n",
        "        con_mat[i] = cm.ravel() # tn, fp, fn, tp\n",
        "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Negative', 'Positive'])\n",
        "        disp.plot(cmap=plt.cm.Blues)\n",
        "        plt.title('Confusion Matrix: {}'.format(class_names[i]))\n",
        "        plt.ylabel('Actual')\n",
        "        plt.xlabel('Predicted')\n",
        "\n",
        "    cm_total = confusion_matrix(true_labels.ravel(), pred.ravel())\n",
        "    disp_total = ConfusionMatrixDisplay(confusion_matrix=cm_total, display_labels=['Negative', 'Positive'])\n",
        "    disp_total.plot(cmap=plt.cm.Blues)\n",
        "    plt.title('Confusion Matrix: Total')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "\n",
        "    return con_mat\n",
        "\n",
        "con_mat = plot_confusion_matrix(true_labels, probs, class_names, threshold_young)\n",
        "print(\"{:20}{:20}{:20}{:20}{:20}\".format('Label', 'True_Negative', 'False_Positive', 'False_Negative', 'True_Positive'))\n",
        "for i in range(4):\n",
        "  print(\"{:20}{:20}{:20}{:20}{:20}\".format(class_names[i], int(con_mat[i, 0]), int(con_mat[i, 1]), int(con_mat[i, 2]), int(con_mat[i, 3])))\n",
        "#print(con_mat)\n",
        "#print(class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoHJ0BHjE_3f"
      },
      "source": [
        "Get best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgDwRLxWE_P4",
        "outputId": "bf1535da-65b7-4e0f-a18b-cd607df25bb9"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import glob\n",
        "import os\n",
        "import sys\n",
        "import argparse\n",
        "import json\n",
        "import itertools\n",
        "\n",
        "def print_helper(seq, verbose, n_print, reverse=False):\n",
        "    for i, model_info in enumerate(sorted(seq, reverse=reverse)):\n",
        "        if verbose:\n",
        "            print(model_info)\n",
        "        else:\n",
        "            print(model_info[1], end=\" \")\n",
        "        if i == n_print:\n",
        "            break\n",
        "\n",
        "\n",
        "def get_best_predictions(path, n_print, verbose):\n",
        "    predictions = []\n",
        "    for timestamp in glob.glob(path + \"/*\"):\n",
        "        for validation_file in glob.glob(timestamp + \"/*-valid_1.npy\"):\n",
        "            basename = os.path.basename(validation_file)\n",
        "            dirname = os.path.dirname(validation_file)\n",
        "            with open(dirname + '/params.json') as json_data:\n",
        "                params = json.load(json_data)\n",
        "                num_models = params[\"num_models\"]\n",
        "            end_index = basename.find(\"-valid_1\")\n",
        "            AUC = float(basename[:end_index])\n",
        "            predictions.append((AUC, dirname, num_models))\n",
        "    print_helper(predictions, verbose, n_print, reverse=True)\n",
        "\n",
        "\n",
        "def get_best_models(path, n, verbose, ungrouped):\n",
        "    # from https://stackoverflow.com/questions/3368969/find-string-between-two-substrings\n",
        "    def find_between(s, first, last):\n",
        "        try:\n",
        "            start = s.index(first ) + len( first )\n",
        "            end = s.index( last, start )\n",
        "            return s[start:end]\n",
        "        except ValueError:\n",
        "            return \"\"\n",
        "\n",
        "    models = []\n",
        "    for checkpoint_path in glob.glob(path + \"/**/*epoch*\"):\n",
        "        val_loss = float(find_between(\n",
        "            checkpoint_path, 'val', '_train'))\n",
        "        models.append((val_loss, checkpoint_path))\n",
        "\n",
        "    groups = itertools.groupby(models,\n",
        "                lambda x: os.path.dirname(x[1]))\n",
        "\n",
        "    models_group_best = []\n",
        "    if ungrouped is True:\n",
        "        models_group_best = models\n",
        "    else:\n",
        "        for _, model in groups:\n",
        "            models_group_best.append(sorted(list(model))[0])\n",
        "\n",
        "    return sorted(models_group_best)[:n]\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    \"\"\"\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\n",
        "        'selection_type',\n",
        "        choices={'model', 'prediction'},\n",
        "        help=\"Whether to get the best models or best predictions\")\n",
        "    parser.add_argument(\n",
        "        'folder',\n",
        "        help=\"path to get best from\")\n",
        "    parser.add_argument('-n', '--n', type=int, default=20)\n",
        "    parser.add_argument('--verbose', action=\"store_true\")\n",
        "    parser.add_argument('--ungrouped', action=\"store_true\")\n",
        "    args = parser.parse_args()\n",
        "    \"\"\"\n",
        "    args = argparse.Namespace(\n",
        "        selection_type=\"model\",\n",
        "        #selection_type=\"prediction\",\n",
        "        folder=\"/content/drive/MyDrive/ML/history_model\",\n",
        "        n=5,\n",
        "        verbose=False,\n",
        "        ungrouped=False\n",
        "    )\n",
        "\n",
        "    if args.selection_type == 'model':\n",
        "        models_group_best = get_best_models(args.folder, args.n, args.verbose, args.ungrouped)\n",
        "        print_helper(models_group_best, args.verbose, args.n, reverse=False)\n",
        "    elif args.selection_type == 'prediction':\n",
        "        get_best_predictions(args.folder, args.n, args.verbose)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
